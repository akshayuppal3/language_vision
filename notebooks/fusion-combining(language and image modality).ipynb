{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Average\n",
    "from keras_contrib.layers import CRF\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "# define documents\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import pickle\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def PCA_with_SVM(X_train,Y_train):\n",
    "    estimators = [('reduce_dim', PCA()), ('clf', SVC() )]\n",
    "    pipe = Pipeline(estimators)\n",
    "    pipe.fit(X_train,Y_train)\n",
    "    return(pipe)\n",
    "def svm_wrapper(X_train,Y_train):\n",
    "    param_grid = [\n",
    "    {'C': [1, 10], 'kernel': ['linear']},\n",
    "    {'C': [1, 10], 'gamma': [0.1,0.01], 'kernel': ['rbf']},]\n",
    "    svm = GridSearchCV(SVC(),param_grid)\n",
    "    svm.fit(X_train, Y_train)\n",
    "    return(svm)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def radom_forest_wrapper(X_train,Y_train):\n",
    "    param_grid = [\n",
    "    { 'max_depth' : [i for i in np.arange(1,10)], \n",
    "       'n_estimators': [j for j in np.arange(1,10)]}]\n",
    "    rand = GridSearchCV(RandomForestClassifier(),param_grid)\n",
    "    rand.fit(X_train,Y_train)\n",
    "    return(rand)\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "def naive_bayes(X_train,Y_train):\n",
    "    clf = BernoulliNB()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    return(clf)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "def mlp_wrapper(X_train,Y_train):\n",
    "    param_grid = [{'hidden_layer_sizes':np.arange(10,100,4),'max_iter':[30] ,'activation':['logistic', 'tanh','relu']}]\n",
    "    mlp = GridSearchCV(MLPClassifier(), param_grid)\n",
    "    mlp.fit(X_train, Y_train)\n",
    "    return(mlp)\n",
    "def boosting(X_train,Y_train):\n",
    "    gb= GradientBoostingClassifier()\n",
    "    gb.fit(X_train, Y_train)\n",
    "    return(gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## tokenize the text..\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Embedding\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "def get_tokens(sentence):\n",
    "#     tokens = nltk.word_tokenize(sentence)  # now using tweet tokenizer\n",
    "    tokens = tknzr.tokenize(sentence)\n",
    "    tokens = [token for token in tokens if (token not in stopwords and len(token) > 1)]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/samarthgoal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/samarthgoal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup env\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_path = \"/home/samarthgoal/language_vision/input/reddit/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_path = \"/home/samarthgoal/embeddings/glove.twitter.27B.100d.txt\" ## change\n",
    "embedding_ff = \"/home/samarthgoal/embeddings/fasttext_100.vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_dir = \"/home/samarthgoal/language_vision\"\n",
    "model_dir = os.path.join(top_dir,\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_rage = pd.read_csv(os.path.join(dir_path,'processed_rage.csv'))\n",
    "df_happy =  pd.read_csv(os.path.join(dir_path,'processed_happy.csv'))\n",
    "df_gore =  pd.read_csv(os.path.join(dir_path,'processed_gore.csv'))\n",
    "df_creepy =  pd.read_csv(os.path.join(dir_path,'processed_creepy.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a random balances dataset of all of the categories\n",
    "length = np.min([len(df_rage),len(df_happy),len(df_creepy),len(df_gore)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## combing all of the dataset\n",
    "df_final = pd.concat([df_rage[:length], df_happy[:length], df_gore[:length], df_creepy[:length]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading the filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## load the filtered df_\n",
    "df_input = pd.read_csv(os.path.join(top_dir,\"input\",\"input_data.csv\"))\n",
    "length = np.min(list(df_input.subreddit.value_counts()))\n",
    "## creating a balanced dataset\n",
    "df_happy =(df_input.loc[df_input.subreddit == \"happy\"])\n",
    "df_gore = (df_input.loc[df_input.subreddit == \"gore\"])\n",
    "df_rage = (df_input.loc[df_input.subreddit == \"rage\"])\n",
    "df_creepy = (df_input.loc[df_input.subreddit == \"creepy\"])\n",
    "df_input = pd.concat([ df_happy[:length], df_rage[:length], df_gore[:length], df_creepy[:length]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a random balances dataset of all of the categories\n",
    "Y_new = df_input['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode the output\n",
    "y = le.fit_transform(Y_new) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_new))\n",
    "print(len(df_input))\n",
    "print(len(img_data_input))\n",
    "print(len(lng_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, test_data, Y_train, Y_test = train_test_split(df_input,y,test_size=0.20,random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### img_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from keras.layers import Lambda, Input\n",
    "from keras.models import Model\n",
    "from keras.backend import tf as ktf\n",
    "import urllib.request\n",
    "from requests.exceptions import ConnectionError\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input as preprocess_input_incept\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input as preprocess_input_res\n",
    "from keras.layers import Maximum\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib3\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## trying with img1\n",
    "# @ param: img url @ return feature vector \n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_img_data(url,size):\n",
    "    try : \n",
    "        response = requests.get(url)\n",
    "        img_data = 0\n",
    "        if (response.status_code == 200):\n",
    "            try:\n",
    "                if (url.endswith('.jpg') or url.endswith('.jpeg') or url.endswith('.png')):\n",
    "                    with urllib.request.urlopen(url) as url1:\n",
    "                        with open('temp.jpg', 'wb') as f:\n",
    "                            f.write(url1.read())\n",
    "                    fh = open('temp.jpg')\n",
    "                    if fh:\n",
    "                        img = image.load_img('temp.jpg', target_size=size) # 224*224\n",
    "                        os.remove('temp.jpg')\n",
    "                        img_data = image.img_to_array(img)\n",
    "                    return img_data\n",
    "            except RuntimeError as e:\n",
    "                return 0  # except runtime error fro file that doesn't exits\n",
    "        return img_data\n",
    "    except IOError:\n",
    "        return 0\n",
    "    except FileNotFoundError as e:\n",
    "        return 0\n",
    "    except ConnectionError as e:\n",
    "        return 0\n",
    "    except urllib.error.HTTPError as e:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samarthgoal/.local/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"fc...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "## convert to 100-D\n",
    "model = ResNet50(weights='imagenet', include_top=True)\n",
    "model_res = Model(input=model.input, output=model.get_layer('fc1000').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samarthgoal/.local/lib/python3.5/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "input = model_res.output\n",
    "# model = Dense(100,activation= 'relu')(input)\n",
    "out = Dense(4, activation='softmax')(input)\n",
    "model_img = Model(input= model_res.input, output=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model_res.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_img.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## load the image data\n",
    "def get_image_input(df,size):\n",
    "    img_data = list()\n",
    "    for index,row in tqdm(df.iterrows(),total=len(df)):\n",
    "        temp = get_img_data(row['url'],size)\n",
    "        img_data.append(temp)\n",
    "    img_data = np.array(img_data)\n",
    "    img_data = preprocess_input_res(np.array(list(img_data)))\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "img_data = get_image_input(train_data,(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "img_data_test = get_image_input(test_data,(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1228, 224, 224, 3)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(308, 224, 224, 3)\n",
      "(1228,)\n"
     ]
    }
   ],
   "source": [
    "print(img_data_test.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 56, 56, 256)  0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 56, 56, 256)  0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 56, 56, 256)  0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 28, 28, 512)  0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 28, 28, 512)  0           add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 28, 28, 512)  0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 28, 28, 512)  0           add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 14, 14, 1024) 0           add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 14, 14, 1024) 0           add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 14, 14, 1024) 0           add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 14, 14, 1024) 0           add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 14, 14, 1024) 0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 14, 14, 1024) 0           add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 7, 7, 2048)   0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 7, 7, 2048)   0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 7, 7, 2048)   0           add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 100)          100100      fc1000[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 4)            404         dense_30[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,737,216\n",
      "Trainable params: 100,504\n",
      "Non-trainable params: 25,636,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_img.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 982 samples, validate on 246 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samarthgoal/.local/lib/python3.5/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "982/982 [==============================] - 136s 139ms/step - loss: 1.4995 - acc: 0.2749 - val_loss: 1.4594 - val_acc: 0.3130\n",
      "Epoch 2/15\n",
      "982/982 [==============================] - 137s 139ms/step - loss: 1.3027 - acc: 0.3941 - val_loss: 1.3196 - val_acc: 0.4187\n",
      "Epoch 3/15\n",
      "982/982 [==============================] - 137s 140ms/step - loss: 1.1542 - acc: 0.5234 - val_loss: 1.2358 - val_acc: 0.4472\n",
      "Epoch 4/15\n",
      "982/982 [==============================] - 137s 139ms/step - loss: 1.0684 - acc: 0.5580 - val_loss: 1.1824 - val_acc: 0.4837\n",
      "Epoch 5/15\n",
      "982/982 [==============================] - 137s 139ms/step - loss: 0.9848 - acc: 0.6405 - val_loss: 1.1501 - val_acc: 0.5203\n",
      "Epoch 6/15\n",
      "982/982 [==============================] - 138s 141ms/step - loss: 0.9385 - acc: 0.6507 - val_loss: 1.1357 - val_acc: 0.5244\n",
      "Epoch 7/15\n",
      "982/982 [==============================] - 137s 140ms/step - loss: 0.8672 - acc: 0.6914 - val_loss: 1.1169 - val_acc: 0.5325\n",
      "Epoch 8/15\n",
      "982/982 [==============================] - 139s 141ms/step - loss: 0.8283 - acc: 0.7057 - val_loss: 1.1051 - val_acc: 0.5447\n",
      "Epoch 9/15\n",
      "982/982 [==============================] - 138s 140ms/step - loss: 0.7796 - acc: 0.7322 - val_loss: 1.1079 - val_acc: 0.5447\n",
      "Epoch 10/15\n",
      "982/982 [==============================] - 138s 141ms/step - loss: 0.7389 - acc: 0.7332 - val_loss: 1.1168 - val_acc: 0.5488\n",
      "Epoch 11/15\n",
      "982/982 [==============================] - 138s 141ms/step - loss: 0.7127 - acc: 0.7373 - val_loss: 1.1219 - val_acc: 0.5488\n",
      "Epoch 12/15\n",
      "982/982 [==============================] - 138s 141ms/step - loss: 0.6663 - acc: 0.7800 - val_loss: 1.1337 - val_acc: 0.5569\n",
      "Epoch 13/15\n",
      "982/982 [==============================] - 137s 140ms/step - loss: 0.6468 - acc: 0.7862 - val_loss: 1.1444 - val_acc: 0.5610\n",
      "Epoch 14/15\n",
      "982/982 [==============================] - 137s 140ms/step - loss: 0.6263 - acc: 0.7831 - val_loss: 1.1512 - val_acc: 0.5650\n",
      "Epoch 15/15\n",
      "982/982 [==============================] - 138s 141ms/step - loss: 0.6134 - acc: 0.7892 - val_loss: 1.1601 - val_acc: 0.5813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe4a4d05518>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_img.fit(img_data,Y_train,verbose=1,nb_epoch=15,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 38s 125ms/step\n",
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.59      0.58        80\n",
      "           1       0.61      0.71      0.65        76\n",
      "           2       0.59      0.44      0.50        77\n",
      "           3       0.54      0.57      0.56        75\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       308\n",
      "   macro avg       0.58      0.58      0.57       308\n",
      "weighted avg       0.58      0.58      0.57       308\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "Y_pred = model_img.predict(img_data_test,verbose=1)\n",
    "y_pred = np.array([np.argmax(pred) for pred in Y_pred])\n",
    "print('  Classification Report:\\n',classification_report(Y_test,y_pred),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## lets train the model independently an then combine the modalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_list = (df_input['title'].apply(get_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3749"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## join the filtered tokens back again to the keras tokenizer which would give vocalb words etc\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "sentences = [' '.join(tokens) for tokens in token_list]\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(token_list)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for idx,tokens in enumerate(token_list):\n",
    "    if len(tokens) > max_len:\n",
    "        max_len = len(tokens)\n",
    "        index = idx\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = train_data['title'].apply(get_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1228"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "senetences = [' '.join(tokens) for tokens in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = vocab_size\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(senetences)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = max_len\n",
    "lng_data = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_encoded_data(tokens,max_len):\n",
    "    senetences = [' '.join(tokens) for tokens in tokens]\n",
    "    # integer encode the documents\n",
    "    encoded_docs = t.texts_to_sequences(senetences)\n",
    "    # pad documents to a max length of 4 words\n",
    "    lng_data = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "    return lng_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the word2vec dict from the dictionary\n",
    "def get_word2vec(file_path):\n",
    "    file = open(embedding_path, \"r\")\n",
    "    if (file):\n",
    "        word2vec = dict()\n",
    "        split = file.read().splitlines()\n",
    "        for line in split:\n",
    "            key = line.split(' ',1)[0] # the first word is the key\n",
    "            value = np.array([float(val) for val in line.split(' ')[1:]])\n",
    "            word2vec[key] = value\n",
    "        return (word2vec)\n",
    "    else:\n",
    "        print(\"invalid fiel path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## dont run it again!!\n",
    "w2v_ff = get_word2vec(embedding_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## load the pre-converted w2v file from models dir\n",
    "w2v = pickle.load(open(os.path.join(model_dir,\"w2v.pkl\"),\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the embedding matrix from the embedding layer\n",
    "from numpy import zeros\n",
    "embedding_matrix_ff = zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "\tembedding_vector = w2v_ff.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix_ff[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## text model\n",
    "input1 = Input(shape=(max_len,))\n",
    "model =  Embedding(vocab_size, 100, weights=[embedding_matrix_ff], input_length=max_length,trainable=False)(input1)\n",
    "model =  Bidirectional( LSTM(units=100,return_sequences=True,dropout=0.25),merge_mode=\"concat\")(model)\n",
    "model = TimeDistributed( Dense(100, activation=\"relu\"))(model)\n",
    "model = Flatten()(model)\n",
    "model = Dense(100, activation = 'relu')(model)\n",
    "out = Dense(4, activation='softmax')(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lng_model_ff = Model(inputs=input1, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lng_model_ff.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 34)                0         \n",
      "_________________________________________________________________\n",
      "embedding_14 (Embedding)     (None, 34, 100)           374900    \n",
      "_________________________________________________________________\n",
      "bidirectional_14 (Bidirectio (None, 34, 200)           160800    \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 34, 100)           20100     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3400)              0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 100)               340100    \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 896,304\n",
      "Trainable params: 521,404\n",
      "Non-trainable params: 374,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lng_model_ff.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1228, 34)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lng_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 982 samples, validate on 246 samples\n",
      "Epoch 1/5\n",
      " 96/982 [=>............................] - ETA: 1s - loss: 0.2239 - acc: 0.9271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samarthgoal/.local/lib/python3.5/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "982/982 [==============================] - 1s 1ms/step - loss: 0.2561 - acc: 0.9145 - val_loss: 0.8245 - val_acc: 0.7276\n",
      "Epoch 2/5\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.2120 - acc: 0.9338 - val_loss: 0.9516 - val_acc: 0.7276\n",
      "Epoch 3/5\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1735 - acc: 0.9358 - val_loss: 0.9572 - val_acc: 0.7154\n",
      "Epoch 4/5\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1847 - acc: 0.9358 - val_loss: 1.0165 - val_acc: 0.7195\n",
      "Epoch 5/5\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1830 - acc: 0.9318 - val_loss: 1.0427 - val_acc: 0.6870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe49ccc6c18>"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lng_model_ff.fit(lng_data,Y_train,verbose=1,validation_split=0.2,nb_epoch = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 34)                0         \n",
      "_________________________________________________________________\n",
      "embedding_14 (Embedding)     (None, 34, 100)           374900    \n",
      "_________________________________________________________________\n",
      "bidirectional_14 (Bidirectio (None, 34, 200)           160800    \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 34, 100)           20100     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3400)              0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 100)               340100    \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 896,304\n",
      "Trainable params: 521,404\n",
      "Non-trainable params: 374,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lng_model_ff.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = test_data['title'].apply(get_tokens)\n",
    "lng_data_test = get_encoded_data(tokens,max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 9s 29ms/step\n",
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68        80\n",
      "           1       0.64      0.76      0.70        76\n",
      "           2       0.84      0.82      0.83        77\n",
      "           3       0.70      0.57      0.63        75\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       308\n",
      "   macro avg       0.72      0.71      0.71       308\n",
      "weighted avg       0.71      0.71      0.71       308\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "Y_pred = lng_model_ff.predict(lng_data_test,verbose=1)\n",
    "y_pred = np.array([np.argmax(pred) for pred in Y_pred])\n",
    "print('  Classification Report:\\n',classification_report(Y_test,y_pred),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 479us/step\n",
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.64      0.67        80\n",
      "           1       0.68      0.71      0.70        76\n",
      "           2       0.90      0.71      0.80        77\n",
      "           3       0.60      0.77      0.68        75\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       308\n",
      "   macro avg       0.72      0.71      0.71       308\n",
      "weighted avg       0.73      0.71      0.71       308\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "Y_pred = lng_model_ff.predict(lng_data_test,verbose=1)\n",
    "y_pred = np.array([np.argmax(pred) for pred in Y_pred])\n",
    "print('  Classification Report:\\n',classification_report(Y_test,y_pred),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 1000)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samarthgoal/.local/lib/python3.5/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \n",
      "/home/samarthgoal/.local/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/samarthgoal/.local/lib/python3.5/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "## lets fuse..\n",
    "model_1 = Model(input=model_img.input, output=model_img.get_layer('dense_30').output)\n",
    "model_2 = Model(input=lng_model.input, output=lng_model.get_layer('dense_38').output)\n",
    "model_1b = Model(input=lng_model_ff.input, output=lng_model_ff.get_layer('dense_41').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1228/1228 [==============================] - 156s 127ms/step\n",
      "1228/1228 [==============================] - 1s 461us/step\n"
     ]
    }
   ],
   "source": [
    "part1_train = model_1.predict(img_data,verbose=1)\n",
    "part2_train = model_2.predict(lng_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1228/1228 [==============================] - 1s 634us/step\n"
     ]
    }
   ],
   "source": [
    "part2b_train = model_1b.predict(lng_data,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "part2u_train = np.maximum(part2_train,part2b_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train = np.hstack(part1,part2)\n",
    "X_train = np.hstack((part1_train,part2u_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 47s 152ms/step\n",
      "308/308 [==============================] - 9s 29ms/step\n"
     ]
    }
   ],
   "source": [
    "part1 = model_1.predict(img_data_test,verbose=1)\n",
    "part2 = model_2.predict(lng_data_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 726us/step\n"
     ]
    }
   ],
   "source": [
    "part2b = model_1b.predict(lng_data_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "part2u = np.maximum(part2,part2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = np.hstack((part1,part2u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 200)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1228, 200)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samarthgoal/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuarcy : 0.775974025974026\n",
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.69      0.73        80\n",
      "           1       0.75      0.86      0.80        76\n",
      "           2       0.88      0.82      0.85        77\n",
      "           3       0.72      0.75      0.73        75\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       308\n",
      "   macro avg       0.78      0.78      0.78       308\n",
      "weighted avg       0.78      0.78      0.78       308\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## getting the scores with late fusion\n",
    "# svm\n",
    "svm = svm_wrapper(X_train,Y_train)\n",
    "Y_pred = svm.predict(X_test)\n",
    "score = accuracy_score(Y_test,Y_pred)\n",
    "print(\"accuarcy :\", score)\n",
    "confusion_matrix(Y_test,Y_pred)\n",
    "print('  Classification Report:\\n',classification_report(Y_test,Y_pred),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Scores.append(0.78)\n",
    "label.append(\"fusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAJQCAYAAAAg+ngHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xu0XXV99/vPlySIBQociEMlSGIflFsgQIxarFJEi5XCGccbqM/jpYp1iFbxMMRLFTl1lMd67Kg+eEHtUSkVqDzSqFG0GrwjCRDQgCgCQqjVgIiCAsb8zh9ZZGzTQHZkz/3b2fv1GiPDNeeae63v3svFeI8551qzWmsBAKCf7XoPAAAw0wkyAIDOBBkAQGeCDACgM0EGANCZIAMA6EyQAQB0JsgAADoTZAAAnc3uPcDW2mOPPdr8+fN7jwEAsEWXXXbZra21uVvabpsLsvnz52flypW9xwAA2KKq+tF4tnPIEgCgM0EGANCZIAMA6GybO4dsc37zm99kzZo1ufvuu3uPsk3bYYcdMm/evMyZM6f3KAAwo0yLIFuzZk123nnnzJ8/P1XVe5xtUmstt912W9asWZMFCxb0HgcAZpRpccjy7rvvzu677y7GHoSqyu67724vIwB0MC2CLIkYmwD+hgDQx6BBVlVHV9W1VXVdVZ26mfsfVVXLq+qKqrqqqv58yHkAAKaiwc4hq6pZSc5M8rQka5KsqKqlrbWrx2z2liTnt9beX1X7J1mWZP6Dfe75p372wT7E77jxjGducZuddtopd95554Q+LwAwMwy5h2xJkutaa9e31u5Ncm6S4zbZpiX5w9HtXZL8x4DzAABMSUMG2Z5Jbh6zvGa0bqzTkrywqtZkw96xVw84z6S4884789SnPjWHHnpoFi5cmH/7t39Lktx4443Zb7/98vKXvzwHHHBAnv70p+fXv/51kmTFihU56KCDsmjRopxyyik58MADkyQf/ehHc9JJJ2187GOOOSYXX3xxkuSVr3xlFi9enAMOOCBve9vbNm6zbNmy7LvvvjnssMPymte8Jsccc0yS5K677spLX/rSLFmyJIcccsjGuQCA/nqf1H9Cko+21uYl+fMkZ1fVf5mpqk6sqpVVtXLt2rWTPuTW2GGHHfKpT30ql19+eZYvX57Xv/71aa0lSX7wgx/kVa96VVavXp1dd901F1xwQZLkJS95ST74wQ9m1apVmTVr1rie5x3veEdWrlyZq666Kl/5yldy1VVX5e67784rXvGKfO5zn8tll12WsX+rd7zjHTnyyCNz6aWXZvny5TnllFNy1113TfwfAADYakMG2S1J9hqzPG+0bqy/THJ+krTWvpVkhyR7bPpArbWzWmuLW2uL587d4gXTu2qt5U1velMOOuigHHXUUbnlllvyk5/8JEmyYMGCLFq0KEly2GGH5cYbb8zPf/7z/PKXv8wTn/jEJMnzn//8cT3P+eefn0MPPTSHHHJIVq9enauvvjrf+9738uhHP3rj94idcMIJG7f/whe+kDPOOCOLFi3KEUcckbvvvjs33XTTRP7qAMDvacgvhl2RZJ+qWpANIXZ8kk1r46YkT03y0araLxuCbGrvAtuCc845J2vXrs1ll12WOXPmZP78+Ru/2+shD3nIxu1mzZq18ZDl/Zk9e3bWr1+/cfm+x7nhhhvyrne9KytWrMhuu+2WF7/4xVv8/rDWWi644II89rGP/X1/NQBgIIPtIWutrUtyUpKLklyTDZ+mXF1Vp1fVsaPNXp/k5VV1ZZJPJHlxu+/43jbqjjvuyMMe9rDMmTMny5cvz49+9KMH3H7XXXfNzjvvnG9/+9tJknPPPXfjffPnz8+qVauyfv363Hzzzbn00kuTJL/4xS+y4447ZpdddslPfvKTfO5zn0uSPPaxj83111+fG2+8MUly3nnnbXysP/uzP8t73/vejYdPr7jiign7nQGAB2fQSye11pZlw8n6Y9e9dcztq5McPtHPO56vqRjKC17wgvzFX/xFFi5cmMWLF2fffffd4s985CMfyctf/vJst912ecpTnpJddtklSXL44YdnwYIF2X///bPffvvl0EMPTZIcfPDBOeSQQ7Lvvvtmr732yuGHb/gTPvShD8373ve+HH300dlxxx3zuMc9buNz/M3f/E1e+9rX5qCDDsr69euzYMGCfOYznxngLwAAbK3a1nZILV68uK1cufJ31l1zzTXZb7/9Ok304N15553ZaaedkiRnnHFGfvzjH+cf//EfH9Rjtdbyqle9Kvvss09e97rXjfvnt/W/JQBMJVV1WWtt8Za26/0pS5J89rOfzaJFi3LggQfma1/7Wt7ylrf83o/1oQ99KIsWLcoBBxyQO+64I694xSsmcFIAYAj2kPE7/C0BYOLYQwYAsI0QZAAAnQkyAIDOBBkAQGeDfg9ZN6ftMsGPd8cWN/njP/7jfPOb35zY5wUAZoTpGWQdiDEA7s/Cjy3sPQKb8Z0Xfaf3CBs5ZDlB7vti14svvjhPecpTctxxx+XRj350Tj311JxzzjlZsmRJFi5cmB/+8IdJkk9/+tN5/OMfn0MOOSRHHXXUxguQr127Nk972tNywAEH5GUve1n23nvv3HrrrUmSf/7nf86SJUuyaNGivOIVr8hvf/vbPr8sADChBNkArrzyynzgAx/INddck7PPPjvf//73c+mll+ZlL3tZ3vve9yZJnvSkJ+WSSy7JFVdckeOPPz7vfOc7kyRvf/vbc+SRR2b16tV59rOfnZtuuinJhu8HO++88/KNb3wjq1atyqxZs3LOOed0+x0BgInjkOUAHve4x+URj3hEkuSP/uiP8vSnPz1JsnDhwixfvjxJsmbNmjzvec/Lj3/849x7771ZsGBBkuTrX/96PvWpTyVJjj766Oy2225Jki996Uu57LLLNl6f8te//nUe9rCHTervBQAMQ5AN4CEPecjG29ttt93G5e222y7r1q1Lkrz61a/OySefnGOPPTYXX3xxTjvttAd8zNZaXvSiF+Xv/u7vBpsbAOjDIctO7rjjjuy5555Jko997GMb1x9++OE5//zzkyRf+MIXcvvttydJnvrUp+aTn/xkfvrTnyZJfvazn+VHP/rRJE8NAAxheu4hG8fXVPR22mmn5TnPeU522223HHnkkbnhhhuSJG9729tywgkn5Oyzz84Tn/jEPPzhD8/OO++cPfbYI3/7t3+bpz/96Vm/fn3mzJmTM888M3vvvXfn3wQAeLBcXHyKueeeezJr1qzMnj073/rWt/LKV74yq1atmrTnn05/S4CpwtdeTE2T8bUX4724+PTcQ7YNu+mmm/Lc5z4369evz/bbb58PfehDvUcCAAYmyKaYffbZJ1dccUXvMQCASeSkfgCAzgQZAEBnggwAoDNBBgDQ2bQ8qX+iP148no/Fvuc978n73//+HHrooVt1jcmXvexlOfnkk7P//vs/mBEBgG3YtAyyHt73vvfl3//93zNv3ryt+rkPf/jDA00EAGwrHLKcAH/1V3+V66+/Ps94xjOyyy675F3vetfG+w488MDceOONueuuu/LMZz4zBx98cA488MCcd955SZIjjjgi933R7Sc+8YksXLgwBx54YN7whjdsfIyddtopb37zm3PwwQfnCU94Qn7yk59M7i8IAAxKkE2AD3zgA3nkIx+Z5cuX53Wve91mt/n85z+fRz7ykbnyyivz3e9+N0cfffTv3P8f//EfecMb3pAvf/nLWbVqVVasWJELL7wwSXLXXXflCU94Qq688so8+clP9mWxADDNCLJJsnDhwnzxi1/MG97whnzta1/LLrvs8jv3r1ixIkcccUTmzp2b2bNn5wUveEG++tWvJkm23377HHPMMUmSww47LDfeeONkjw8ADEiQTbDZs2dn/fr1G5fvvvvuJMljHvOYXH755Vm4cGHe8pa35PTTTx/3Y86ZMydVlSSZNWtW1q1bN7FDAwBdCbIJNn/+/Fx++eVJkssvvzw33HBDkg2HJP/gD/4gL3zhC3PKKads3OY+S5YsyVe+8pXceuut+e1vf5tPfOITecpTnjLp8wMAk29afspyMq7efn+e9axn5eMf/3gOOOCAPP7xj89jHvOYDTN95zs55ZRTst1222XOnDl5//vf/zs/94hHPCJnnHFG/vRP/zSttTzzmc/Mcccd1+NXAAAmWbXWes+wVRYvXtzu+1Tifa655prst99+nSaaXvwtASbeRH8/JhNjMnbgVNVlrbXFW9rOIUsAgM4EGQBAZ9MmyLa1Q69Tkb8hAPQxLYJshx12yG233SYoHoTWWm677bbssMMOvUcBgBlnWnzKct68eVmzZk3Wrl3be5Rt2g477LDV1+IEAB68aRFkc+bMyYIFC3qPAQDwe5kWhywBALZlggwAoDNBBgDQmSADAOhMkAEAdCbIAAA6E2QAAJ0JMgCAzgQZAEBnggwAoDNBBgDQmSADAOhMkAEAdCbIAAA6E2QAAJ0JMgCAzgQZAEBnggwAoLPZvQeYiuaf+tneI7AZN57xzN4jAMAg7CEDAOhMkAEAdDZokFXV0VV1bVVdV1Wnbub+f6iqVaN/36+qnw85DwDAVDTYOWRVNSvJmUmelmRNkhVVtbS1dvV927TWXjdm+1cnOWSoeQAApqoh95AtSXJda+361tq9Sc5NctwDbH9Ckk8MOA8AwJQ0ZJDtmeTmMctrRuv+i6raO8mCJF++n/tPrKqVVbVy7dq1Ez4oAEBPU+Wk/uOTfLK19tvN3dlaO6u1tri1tnju3LmTPBoAwLCGDLJbkuw1ZnneaN3mHB+HKwGAGWrIIFuRZJ+qWlBV22dDdC3ddKOq2jfJbkm+NeAsAABT1mBB1lpbl+SkJBcluSbJ+a211VV1elUdO2bT45Oc21prQ80CADCVDXrppNbasiTLNln31k2WTxtyBgCAqW6qnNQPADBjCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdDRpkVXV0VV1bVddV1an3s81zq+rqqlpdVf8y5DwAAFPR7KEeuKpmJTkzydOSrEmyoqqWttauHrPNPknemOTw1trtVfWwoeYBAJiqhtxDtiTJda2161tr9yY5N8lxm2zz8iRnttZuT5LW2k8HnAcAYEoaMsj2THLzmOU1o3VjPSbJY6rqG1V1SVUdPeA8AABT0mCHLLfi+fdJckSSeUm+WlULW2s/H7tRVZ2Y5MQkedSjHjXZMwIADGrIPWS3JNlrzPK80bqx1iRZ2lr7TWvthiTfz4ZA+x2ttbNaa4tba4vnzp072MAAAD0MGWQrkuxTVQuqavskxydZusk2F2bD3rFU1R7ZcAjz+gFnAgCYcgYLstbauiQnJbkoyTVJzm+tra6q06vq2NFmFyW5raquTrI8ySmttduGmgkAYCoa9Byy1tqyJMs2WffWMbdbkpNH/wAAZiTf1A8A0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM5m9x4A2IadtkvvCdic0+7oPQGwlewhAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQ2aJBV1dFVdW1VXVdVp27m/hdX1dqqWjX697Ih5wEAmIpmD/XAVTUryZlJnpZkTZIVVbW0tXb1Jpue11o7aag5AACmuiH3kC1Jcl1r7frW2r1Jzk1y3IDPBwCwTRoyyPZMcvOY5TWjdZt6VlVdVVWfrKq9BpwHAGBK6n1S/6eTzG+tHZTki0k+trmNqurEqlpZVSvXrl07qQMCAAxtyCC7JcnYPV7zRus2aq3d1lq7Z7T44SSHbe6BWmtntdYWt9YWz507d5BhAQB6GTLIViTZp6oWVNX2SY5PsnTsBlX1iDGLxya5ZsB5AACmpME+ZdlaW1dVJyW5KMmsJP/UWltdVacnWdlaW5rkNVV1bJJ1SX6W5MVDzQMAMFUNFmRJ0lpblmTZJuveOub2G5O8ccgZAACmut4n9QMAzHiCDACgM0EGANCZIAMA6EyQAQB0JsgAADoTZAAAnQkyAIDOBBkAQGeCDACgM0EGANCZIAMA6EyQAQB0JsgAADoTZAAAnQkyAIDOBBkAQGeCDACgM0EGANCZIAMA6EyQAQB0JsgAADoTZAAAnQkyAIDOBBkAQGeCDACgM0EGANCZIAMA6EyQAQB0JsgAADoTZAAAnW0xyKrq8KracXT7hVX17qrae/jRAABmhvHsIXt/kl9V1cFJXp/kh0k+PuhUAAAzyHiCbF1rrSU5Lsn/aq2dmWTnYccCAJg5Zo9jm19W1RuT/Pckf1JV2yWZM+xYAAAzx3j2kD0vyT1JXtpa+88k85L8/aBTAQDMIFsMslGEXZDkIaNVtyb51JBDAQDMJOP5lOXLk3wyyQdHq/ZMcuGQQwEAzCTjOWT5qiSHJ/lFkrTWfpDkYUMOBQAwk4wnyO5prd1730JVzU7ShhsJAGBmGU+QfaWq3pTkoVX1tCT/muTTw44FADBzjCfITk2yNsl3krwiybIkbxlyKACAmeQBv4esqmYl+Xhr7QVJPjQ5IwEAzCwPuIestfbbJHtX1faTNA8AwIwznm/qvz7JN6pqaZK77lvZWnv3YFMBAMwg4wmyH47+bRfXsAQAmHBbDLLW2tuTpKp2Gi3fOfRQAAAzyXi+qf/Aqroiyeokq6vqsqo6YPjRAABmhvF87cVZSU5ure3dWts7yevjE5cAABNmPEG2Y2tt+X0LrbWLk+w42EQAADPMuD5lWVV/k+Ts0fILs+GTlwAATIDx7CF7aZK5Sf53kguS7DFaBwDABBjPpyxvT/KaSZgFAGBGGs+nLL9YVbuOWd6tqi4adiwAgJljPIcs92it/fy+hdEes4cNNxIAwMwyniBbX1WPum+hqvZO0oYbCQBgZhnPpyzfnOTrVfWVJJXkT5KcOOhUAAAzyHhO6v98VR2a5AmjVa9trd067FgAADPHeE7qPzzJr1trn0mya5I3jQ5bblFVHV1V11bVdVV16gNs96yqalW1eNyTAwBME+M5h+z9SX5VVQcnOTnJD5N8fEs/VFWzkpyZ5BlJ9k9yQlXtv5ntdk7y10m+vRVzAwBMG+MJsnWttZbkuCRnttbOTLLzOH5uSZLrWmvXt9buTXLu6DE29f8k+Z9J7h7nzAAA08p4guyXVfXGbLhk0merarskc8bxc3smuXnM8prRuo1G56bt1Vr77AM9UFWdWFUrq2rl2rVrx/HUAADbjvEE2fOS3JPkL1tr/5lkXpK/f7BPPAq7dyd5/Za2ba2d1Vpb3FpbPHfu3Af71AAAU8p4PmX5n9kQTvct35RxnEOW5JYke41Znjdad5+dkxyY5OKqSpKHJ1laVce21laO4/EBAKaF8ewh+32tSLJPVS2oqu2THJ9k6X13ttbuaK3t0Vqb31qbn+SSJGIMAJhxBguy1tq6JCcluSjJNUnOb62trqrTq+rYoZ4XAGBbM55v6t+oqg5trV0+3u1ba8uSLNtk3VvvZ9sjtmYWAIDpYmv3kH14kCkAAGawrQ2yGmQKAIAZbGuD7O2DTAEAMINtVZC11i5Mkqrad5hxAABmnt/3U5ZfmNApAABmsPv9lGVVvef+7kqy6zDjAADMPA/0tRcvyYbLGt2zmftOGGYcAICZ54GCbEWS77bWvrnpHVV12mATAQDMMA8UZM9Ocvfm7mitLRhmHACAmeeBTurfqbX2q0mbBABghnqgILvwvhtVdcEkzAIAMCM9UJCN/Vb+Rw89CADATPVAQdbu5zYAABPogU7qP7iqfpENe8oeOrqd0XJrrf3h4NMBAMwA9xtkrbVZkzkIAMBM9fteOgkAgAkiyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhs0yKrq6Kq6tqquq6pTN3P/X1XVd6pqVVV9var2H3IeAICpaLAgq6pZSc5M8owk+yc5YTPB9S+ttYWttUVJ3pnk3UPNAwAwVQ25h2xJkutaa9e31u5Ncm6S48Zu0Fr7xZjFHZO0AecBAJiSZg/42HsmuXnM8pokj990o6p6VZKTk2yf5MgB5wEAmJK6n9TfWjuztfZHSd6Q5C2b26aqTqyqlVW1cu3atZM7IADAwIYMsluS7DVmed5o3f05N8n/ubk7WmtntdYWt9YWz507dwJHBADob8ggW5Fkn6paUFXbJzk+ydKxG1TVPmMWn5nkBwPOAwAwJQ12DllrbV1VnZTkoiSzkvxTa211VZ2eZGVrbWmSk6rqqCS/SXJ7khcNNQ8AwFQ15En9aa0tS7Jsk3VvHXP7r4d8fgCAbUH3k/oBAGY6QQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0JkgAwDoTJABAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMAKAzQQYA0NmgQVZVR1fVtVV1XVWdupn7T66qq6vqqqr6UlXtPeQ8AABT0WBBVlWzkpyZ5BlJ9k9yQlXtv8lmVyRZ3Fo7KMknk7xzqHkAAKaqIfeQLUlyXWvt+tbavUnOTXLc2A1aa8tba78aLV6SZN6A8wAATElDBtmeSW4es7xmtO7+/GWSz23ujqo6sapWVtXKtWvXTuCIAAD9TYmT+qvqhUkWJ/n7zd3fWjurtba4tbZ47ty5kzscAMDAZg/42Lck2WvM8rzRut9RVUcleXOSp7TW7hlwHgCAKWnIPWQrkuxTVQuqavskxydZOnaDqjokyQeTHNta++mAswAATFmDBVlrbV2Sk5JclOSaJOe31lZX1elVdexos79PslOSf62qVVW19H4eDgBg2hrykGVaa8uSLNtk3VvH3D5qyOcHANgWTImT+gEAZjJBBgDQmSADAOhMkAEAdCbIAAA6E2QAAJ0JMgCAzgQZAEBnggwAoDNBBgDQmSADAOhMkAEAdCbIAAA6E2QAAJ0JMgCAzgQZAEBnggwAoDNBBgDQmSADAOhMkAEAdCbIAAA6E2QAAJ0JMgCAzgQZAEBnggwAoDNBBgDQmSADAOhMkAEAdCbIAAA6E2QAAJ0JMgCAzgQZAEBnggwAoDNBBgDQmSADAOhMkAEAdCbIAAA6E2QAAJ0JMgCAzgQZAEBnggwAoDNBBgDQmSADAOhMkAEAdCbIAAA6E2QAAJ0JMgCAzgQZAEBnggwAoDNBBgDQmSADAOhMkAEAdCbIAAA6E2QAAJ0JMgCAzgQZAEBnggwAoLNBg6yqjq6qa6vquqo6dTP3P7mqLq+qdVX17CFnAQCYqgYLsqqaleTMJM9Isn+SE6pq/002uynJi5P8y1BzAABMdbMHfOwlSa5rrV2fJFV1bpLjklx93wattRtH960fcA4AgCltyEOWeya5eczymtG6rVZVJ1bVyqpauXbt2gkZDgBgqtgmTupvrZ3VWlvcWls8d+7c3uMAAEyoIYPsliR7jVmeN1oHAMAYQwbZiiT7VNWCqto+yfFJlg74fAAA26TBgqy1ti7JSUkuSnJNkvNba6ur6vSqOjZJqupxVbUmyXOSfLCqVg81DwDAVDXkpyzTWluWZNkm69465vaKbDiUCQAwY20TJ/UDAExnggwAoDNBBgDQmSADAOhMkAEAdCbIAAA6E2QAAJ0JMgCAzgQZAEBnggwAoDNBBgDQmSADAOhMkAEAdCbIAAA6E2QAAJ0JMgCAzgQZAEBnggwAoDNBBgDQmSADAOhMkAEAdCbIAAA6E2QAAJ0JMgCAzgQZAEBnggwAoDNBBgDQmSADAOhMkAEAdCbIAAA6E2QAAJ0JMgCAzgQZAEBnggwAoDNBBgDQmSADAOhMkAEAdCbIAAA6E2QAAJ0JMgCAzgQZAEBnggwAoDNBBgDQmSADAOhMkAEAdCbIAAA6E2QAAJ0JMgCAzgQZAEBnggwAoDNBBgDQmSADAOhMkAEAdCbIAAA6E2QAAJ0JMgCAzgQZAEBngwZZVR1dVddW1XVVdepm7n9IVZ03uv/bVTV/yHkAAKaiwYKsqmYlOTPJM5Lsn+SEqtp/k83+MsntrbX/luQfkvzPoeYBAJiqhtxDtiQw5jlHAAAGOElEQVTJda2161tr9yY5N8lxm2xzXJKPjW5/MslTq6oGnAkAYMoZMsj2THLzmOU1o3Wb3aa1ti7JHUl2H3AmAIApZ3bvAcajqk5McuJo8c6qurbnPNuYPZLc2nuIiVDT64D2tHldppHp85q8fVodaJg+r8v0MW1ek3rxpLxX9h7PRkMG2S1J9hqzPG+0bnPbrKmq2Ul2SXLbpg/UWjsryVkDzTmtVdXK1tri3nPwu7wuU4/XZGryukw9XpNhDHnIckWSfapqQVVtn+T4JEs32WZpkheNbj87yZdba23AmQAAppzB9pC11tZV1UlJLkoyK8k/tdZWV9XpSVa21pYm+UiSs6vquiQ/y4ZoAwCYUQY9h6y1tizJsk3WvXXM7buTPGfIGXCod4ryukw9XpOpyesy9XhNBlCOEAIA9OXSSQAAnQmyaaCq/qmqflpV372f+6uq3jO6RNVVVXXoZM84E43jdTmiqu6oqlWjf2/d3HZMnKraq6qWV9XVVbW6qv56M9t4v0yicb4m3iuTrKp2qKpLq+rK0evy9s1s4/KHE2ib+B4ytuijSf5Xko/fz/3PSLLP6N/jk7x/9L8M66N54NclSb7WWjtmcsYhybokr2+tXV5VOye5rKq+2Fq7esw23i+TazyvSeK9MtnuSXJka+3OqpqT5OtV9bnW2iVjttl4+cOqOj4bLn/4vB7DTgf2kE0DrbWvZsOnVO/PcUk+3ja4JMmuVfWIyZlu5hrH68Ika639uLV2+ej2L5Nck/96BRHvl0k0zteESTb6//+do8U5o3+bnnTu8ocTSJDNDOO5jBV9PHF0SOBzVXVA72FmktHhlUOSfHuTu7xfOnmA1yTxXpl0VTWrqlYl+WmSL7bW7ve94vKHD54gg34uT7J3a+3gJO9NcmHneWaMqtopyQVJXtta+0Xvedjia+K90kFr7bettUXZcKWdJVV1YO+ZpjNBNjOM5zJWTLLW2i/uOyQw+s6+OVW1R+expr3R+TAXJDmntfa/N7OJ98sk29Jr4r3SV2vt50mWJzl6k7s2vlce6PKHjI8gmxmWJvkfo0+PPSHJHa21H/ceaqarqoffd75FVS3Jhvej/5gNaPT3/kiSa1pr776fzbxfJtF4XhPvlclXVXOratfR7YcmeVqS722ymcsfTiCfspwGquoTSY5IskdVrUnytmw4ATOttQ9kw9US/jzJdUl+leQlfSadWcbxujw7ySural2SXyc53n/MBnd4kv+e5Dujc2OS5E1JHpV4v3QyntfEe2XyPSLJx6pqVjYE8Pmttc+4/OFwfFM/AEBnDlkCAHQmyAAAOhNkAACdCTIAgM4EGQBAZ4IMmNGq6sYtfcno2G2q6puj/51fVc+fjBmB6U+QAWyF1tofj27OTyLIgAkhyIBtzmjv1Peq6qNV9f2qOqeqjqqqb1TVD6pqSVX9H1V1YVVdVVWXVNVBo5/dvaq+UFWrq+rDSWrM415YVZeN7jvxfp77ztHNM5L8SVWtqqrXVdVXq2rRmO2+XlUHD/hnAKYRQQZsq/5bkv83yb6jf89P8qQk/3c2fNP725Nc0Vo7aLT88dHPvS3J11trByT5VEbfCD/y0tbaYUkWJ3lNVe3+AM9/apKvtdYWtdb+IRu+tfzFSVJVj0myQ2vtyon4RYHpT5AB26obWmvfaa2tT7I6yZdGl9P5TjYcTnxSkrOTpLX25SS7V9UfJnlykn8erf9sktvHPOZrqurKJJdkw0WT99mKef41yTGjC2W/NMlHf/9fDZhpXMsS2FbdM+b2+jHL67Phv22/2ZoHq6ojkhyV5ImttV9V1cVJdhjvz49+5otJjkvy3CSHbc3zAzObPWTAdPW1JC9INsbWra21XyT5akYn41fVM5LsNtp+lyS3j8Jq3yRP2MLj/zLJzpus+3CS9yRZ0Vq7/b/+CMDmCTJgujotyWFVdVU2nID/otH6tyd5clWtTvJ/JblptP7zSWZX1TWj7S/ZwuNfleS3VXVlVb0uSVprlyX5RZL/byJ/EWD6qw2nXADwYFXVI5NcnGTf0bltAONiDxnABKiq/5Hk20neLMaArWUPGQBAZ/aQAQB0JsgAADoTZAAAnQkyAIDOBBkAQGeCDACgs/8fxWEdSKoUU80AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for idx,score in enumerate(Scores):\n",
    "    plt.bar((1+idx),score,label = label[idx],width=0.5)\n",
    "plt.xlabel(\"modality\")\n",
    "plt.ylabel(\"F1- scores\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for idx,score in enumerate(Scores):\n",
    "    plt.bar((1+idx),score,label = label[idx],width=0.5)\n",
    "plt.xlabel(\"pooling type\")\n",
    "plt.ylabel(\"scores\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = [lng_data_test,img_data_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lng_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 376us/step\n",
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.28      0.27        80\n",
      "           1       0.23      0.20      0.21        76\n",
      "           2       0.24      0.22      0.23        77\n",
      "           3       0.21      0.25      0.23        75\n",
      "\n",
      "   micro avg       0.24      0.24      0.24       308\n",
      "   macro avg       0.24      0.24      0.24       308\n",
      "weighted avg       0.24      0.24      0.24       308\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "Y_pred = model.predict(X_test,verbose=1)\n",
    "y_pred = np.array([np.argmax(pred) for pred in Y_pred])\n",
    "print('  Classification Report:\\n',classification_report(Y_test,y_pred),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dump the w2v vec file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(model_dir,\"w2v.pkl\"),\"wb\") as f:\n",
    "    pickle.dump(w2v,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## dump the image array\n",
    "with open(os.path.join(model_dir,\"img_data.pkl\"),\"wb\") as f:\n",
    "    pickle.dump(img_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## dump the model\n",
    "# serialize model to JSON\n",
    "def dump_model(model,path):\n",
    "    model_json = model.to_json()\n",
    "    with open(path, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(os.path.join(model_dir,\"model.h5\"))\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(model_dir,\"img_model.json\")\n",
    "dump_model(model_img,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(model_dir,\"lng_model.json\")\n",
    "dump_model(lng_model,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
